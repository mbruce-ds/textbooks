\chapter{Growth of Functions}
\section{Asymptotic notation}

\qn{3.1-1} Let $f(n)$ and $g(n)$ be asymptotically nonnegative functions. Using the basic definition of $\Theta$-notation, prove that $\max(f(n), g(n)) = \Theta(f(n) + g(n))$.

\sol Recall that $$\max(f(n), g(n)) = \frac{f(n) + g(n) + |f(n) - g(n)|}{2}$$ and that $$0 \leq |f(n) - g(n)| \leq |f(n)| + |g(n)|.$$ Substituting these in to the definition of $\Theta(f(n) + g(n))$ yields
\begin{alignat*}{2}
    0 \leq c_1 (f(n) + g(n)) \leq & \max(f(n), g(n)) &&\leq c_2(f(n) + g(n)), \\
    2c_1(f(n) + g(n)) \leq & f(n) + g(n) + |f(n) - g(n)| &&\leq 2c_2 (f(n) + g(n)). \\
\end{alignat*}
Setting $c_1 = 1/2$ and $c_2 = 1$ yields the desired inequality, as follows by the inequalities with $|f(n) - g(n)|$ above.\qed

\qn{3.1-2}

Show that for any real constants $a$ and $b$, where $b > 0$, $$(n+a)^b = \Theta(n^b).$$

\sol For $(n+a)^b = \Theta(n^b)$, we need to show that there exist $c_1, c_2, n_0 > 0$ such that $0 \leq c_1 n^b \leq (n + a)^b \leq c_2n^b$. We can manipulate this inequality to yield
\begin{alignat*}{2}
    c_1 n^b \leq \, &(n + a)^b &&\leq c_2 n^b, \\
    c_1 \leq \, &\frac{(n+a)^b}{n^b} &&\leq c_2, \\
    c_1 \leq \, &\left(\frac{n+a}{n}\right)^b &&\leq c_2, \\
    \sqrt[b]{c_1} \leq \, &1 + \frac{a}{n} &&\leq \sqrt[b]{c_2}, \\
    \sqrt[b]{c_1} - 1 \leq \, &\frac{a}{n} &&\leq \sqrt[b]{c_2} - 1.
\end{alignat*}
If $a \geq 0$, then setting $c_1 = 1$, $c_2 = (a + 1)^b$, for $n_0 = 1$, the inequality is satisfied. If $a < 0$, then for $c_1 = \frac{1}{2^b}$, $c_2 = 1$, and $n_0 > -2a$, the inequality is satisfied.\qed


\qn{3.1-3} Explain why the statement, ``The running time of the algorithm $A$ is at least $O(n^2)$'' is meaningless.

\sol $O$-notation provides an asymptotic upper bound for a function, that is, that $f(n) \leq cg(n)$ for all $n \geq N_0$. To say that a function is ``at least $O(n^2)$'' would imply that a function is greater than some upper bound in $O(n^2)$, which gives no information. For example, it can be greater than a constant $g(n) = c \in O(n^2)$. (the wording for this question being so confusing is why I hate the abuse of notation saying a function ``is'' $O(f(n))$ rather than a function is ``in'' $O(f(n))$... like what does it mean for the running time to be at least a set? Or maybe that's the point.)\qed

\qn{3.1-4} Is $2^{n+1} = O(2^n)$? Is $2^{2n} = O(2^n)$?

\sol Since $2^{n+1} = 2\cdot 2^n$, we have $2^{n+1} = O(2^n)$ by choice of $c = 2, \, n_0 = 1$.

Since $2^{2n} = 2^n \cdot 2^n$, for $2^{2n} = O(2^n)$ we would need some constant $c$ such that $2^{2n} \leq c\cdot 2^n \implies 2^n \leq c$, which is not true for any constant choice of $c$ for all $n \geq n_0$ for any $n_0$. Thus $2^{2n} \neq O(2^n).$\qed

\qn{3.1-5} Prove Theorem 3.1.

\pf Suppose $f(n) = \Theta(g(n))$. Then there exist $c_1, c_2, n_0$ such that $0 \leq c_1 g(n) \leq f(n) \leq c_2 g(n)$ for all $n \geq n_0$. It is then clear that for $c = c_1, n_0 = n_0$, we have $0 \leq f(n) \leq c g(n)$, so $f(n) = O(g(n))$ and for $c = c_2, n_0 = n_0$, we have $0 \leq c g(n) \leq f(n)$, so $f(n) = \Omega(g(n))$.

Suppose $f(n) = O(g(n))$ and $f(n) = \Omega(g(n))$. Let $(c_O, n_O)$ be a choice of $c, n_0$ satisfying $f(n) = O(g(n))$ and let $(c_\Omega, n_\Omega)$ be a choice of $c, n_0$ satisfying $f(n) = \Omega(g(n))$. Choose $n_0 = \max\{n_O, n_\Omega\}$, $c_1 = C_\Omega$, and $c_2 = C_O$. For these choices of constants we have that $0 \leq c_1 g(n) \leq f(n) \leq c_2 g(n)$ for all $n \geq n_0$, and thus $f(n) = \Theta(g(n))$.\qed

\qn{3.1-6} Prove that the running time of an algorithm is $\Theta(g(n))$ if and only if its worst-case running time is $O(g(n))$ and its best-case running time is $\Omega(g(n))$.

\pf Suppose the running time $f(n)$ of an algorithm is $\Theta(g(n))$. Then $f(n) \in O(g(n))$ and $f(n) \in \Omega(g(n))$. By the former, we have that $0 \leq f(n) \leq cg(n)$, so the runtime can't get any worse than $O(g(n))$, and by the latter we have that $0 \leq cg(n) \leq f(n)$, so the runtime can't get any better than $\Omega(g(n))$. 

Suppose the running time of an algorithm $f(n)$ has worst-case running time $O(g(n))$ and best-case running time $\Omega(g(n))$. By the former, we have $f(n) \leq cg(n)$ (runtime can't get any worse than $g(n)$), and by the latter we have $c'g(n) \leq f(n)$ (runtime can't get any better than $g(n)$). Together this clearly yields that $f(n) = \Theta(g(n))$. \qed

\qn{3.1-7} Prove that $o(g(n)) \cap \omega(g(n))$ is the empty set.

\pf Suppose $f \in o(g(n)) \cap \omega(g(n))$. Since $f \in o(g(n))$, for any $c > 0$ there exists $n_0$ such that $0 \leq f(n) < cg(n)$. Since $f \in \omega(g(n))$, for any $c > 0$ there exists $n'_0$ such that $0 \leq cg(n) < f(n)$. Take $N = \max\{n_0, n'_0\}$. Then for all $n \geq N$, we have $0 \leq cg(n) < f(n) < cg(n)$, a contradiction.\qed

\qn{3.1-8} We can extend our notation to the case of two parameters $n$ and $m$ that can go to infinity independently at different rates. For a given function $g(n,m)$, we denote by $O(g(n,m))$ the set of functions
\begin{align*}
    O(g(n,m)) = \{f(n,m) \,  : \, & \text{there exist positive constants } c, n_0, \text{ and } m_0 \\
    & \text{such that } 0 \leq f(n,m) \leq cg(n,m) \\
    & \text{for all }n \geq n_0 \text{ or } m \geq m_0\}.
\end{align*}
Give corresponding definitions for $\Omega(g(n,m))$ and $\Theta(g(n,m))$.

\sol 
\begin{align*}
    \Omega(g(n,m)) = \{f(n,m) \, : \, & \text{there exist positive constants } c, n_0, \text{ and } m_0 \\
    & \text{such that } 0 \leq cg(n,m) \leq f(n,m) \\
    & \text{for all } n \geq n_0 \text{ or } m \geq m_0\}.
\end{align*}

\begin{align*}
    \Theta(g(n,m)) = \{f(n,m) \, : \, & \text{there exist positive constants } c_1, c_2, n_0, \text{ and } m_0 \\
    & \text{such that } 0 \leq c_1 g(n,m) \leq f(n,m) \leq c_2 g(n,m) \\
    & \text{for all } n \geq n_0 \text{ or } m \geq m_0\}.
\end{align*}\qed

\section{Standard notations and common functions}

\qn{3.2-1} Show that if $f(n)$ and $g(n)$ are monotonically increasing functions, then so are the functions $f(n) + g(n)$ and $f(g(n))$, and if $f(n)$ and $g(n)$ are in addition nonnegative, then $f(n) \cdot g(n)$ is monotonically increasing.

\sol Suppose $f, g$ are monotonically increasing, so $m \leq n$ implies $f(m) \leq f(n)$ and $g(m) \leq g(n)$. Then we have that $f(m) + g(m) \leq f(n) + g(m) \leq f(n) + g(n)$, so $f + g$ is monotonically increasing. In addition, since $m \leq n$ implies $g(m) \leq g(n)$, plugging this in to $f$ (which is monotonically increasing) yields $f(g(m)) \leq f(g(n))$, so $f\circ g$ is monotonically increasing.\qed

\qn{3.2-2} Prove equation (3.16)

\pf
\begin{align*}
    a^{\log_b c} &= b^{\left(\log_b a^{\log_b c}\right)} \\
    &= b^{\left(\log_b a \log_b c\right)} \\
    &= b^{\left(\log_b c^{\log_b a}\right)} \\
    &= c^{\log_b a}.
\end{align*}\qed

\qn{3.2-3} Prove equation (3.19). Also prove that $n! = \omega(2^n)$ and $n! = o(n^n)$.

\pf By Stirling's approximation, we have
\begin{align*}
    \lg (n!) &= \lg\left(\sqrt{2\pi n} \left(\frac{n}{e}\right)^n \left(1 + \Theta\left(\frac{1}{n}\right)\right)\right)\\
    &= \lg(\sqrt{2\pi n}) + n (\lg n - \lg e) + \lg\left(1 + \Theta\left(\frac{1}{n}\right)\right)\\
    &= \Theta(n \lg n).
\end{align*}

For $n! = \omega(2^n)$, let $c > 0$ and let $n_0 = \max\{2\cdot\lceil c\rceil, 4\}$. Observe that for all $n \geq n_0$, $n! = n\cdot(n-1)\cdots n_0 \cdots 2\cdot 1 = 2(n \cdot (n-1) \cdots (n_0 / 2) \cdots 2 \cdot 1) > 2(2\cdot 2 \cdots 2\cdot 1) = 2^n$.

For $n! = o(n^n)$, let $c > 0$ and let $n_0 = \max\{2\cdot \lceil c \rceil, 4\}$. Observe that for all $n \geq n_0$, $n! = n\cdot (n-1) \cdots n_0 \cdots 2 \cdot 1 < c (n \cdots c \cdots 2 \cdot 1) < c\cdot n^n$, thus $n! = o(n^n)$.
\qed

\qn{3.2-4 *} Is the function $\lceil \lg n \rceil !$ polynomially bounded? Is the function $\lceil \lg \lg n \rceil !$ polynomially bounded?

\sol \qed

\qn{3.2-5 *} Which is asymptotically larger: $\lg(\lg ^* n)$ or $\lg ^* (\lg n)$

\sol \qed

\qn{3.2-6} Show that the golden ratio $\phi$ and its conjugate $\hat{\phi}$ both satisfy the equation $x^2 = x + 1$.

\sol Given $\phi = \frac{1 + \sqrt{5}}{2}$, we have $\phi^2 = \frac{3}{2} + \frac{\sqrt{5}}{2} = \frac{1 + \sqrt{5}}{2} + 1$. Thus, $\phi$ satisfies $x^2 = x + 1$.

Given $\hat\phi = \frac{1 - \sqrt{5}}{2}$, we have $\hat\phi^2 = \frac{3}{2} - \frac{\sqrt{5}}{2} = 1 + \frac{1 - \sqrt{5}}{2}$. Thus, $\hat\phi$ satisfies $x^2 = x + 1$.\qed

\qn{3.2-7} Prove by induction that the $i$th Fibonacci number satisfies the equality $$F_i = \frac{\phi^i - \hat{\phi}^i}{\sqrt{5}},$$ where $\phi$ is the golden ratio and $\hat{\phi}$ is its conjugate.

\pf For $n = 0$, we have $F_0 = \frac{1 - 1}{\sqrt{5}} = 0$, as desired. For $n = 1$, we have $F_1 = \frac{\phi - \hat\phi}{\sqrt{5}} = \frac{\frac{1}{2} + \frac{\sqrt{5}}{2} - \frac{1}{2} + \frac{\sqrt{5}}{2}}{\sqrt{5}} = 1$, as desired.

Suppose the equality is true for all $n \leq N$. Let $n = N+1$. Notice that by question 3.2-6, $\phi$ and $\hat \phi$ satisfy $x^{N+1} = x^N + x^{N-1}$. Then we have
\begin{align*}
    F_{N+1} &= F_N + F_{N-1} \\
    &= \frac{\phi^N - \hat\phi^N}{\sqrt{5}} + \frac{\phi^{N-1} - \hat\phi^{N-1}}{\sqrt{5}} \\
    &= \frac{\phi^N + \phi^{N-1} - (\hat\phi^N + \hat\phi^{N-1})}{\sqrt{5}} \\
    &= \frac{\phi^{N+1} - \hat\phi^{N+1}}{\sqrt{5}}.
\end{align*}

Thus, by induction, $F_i = \frac{\phi^i - \hat\phi^i}{\sqrt{5}}$ as desired.\qed

\qn{3.2-8} Show that $k \ln k = \Theta(n)$ implies $k = \Theta(n / \ln n)$.

\sol By the symmetry property of asymptotics, we have $f(n) = \Theta(g(n))$ if and only if $g(n) = \Theta(f(n))$. Since $k \ln k = \Theta(n)$, we can use the symmetry property to obtain $n = \Theta(k \ln k)$. Taking the logarithm of both sides, we obtain $\ln n = \Theta(\ln k + \ln \ln k) = \Theta(\ln k)$. Dividing $n = \Theta(k \ln k)$ by this yields $\frac{n}{\ln n} = \Theta(k)$. Using the symmetry property again yields $k = \Theta(\frac{n}{\ln n})$.\qed

\section{Problems}

\qn{3-1} \textbf{Asymptotic behavior of polynomials}

Let $$p(n) = \sum_{i=0}^d a_i n^i,$$ where $a_d > 0$, be a degree-$d$ polynomial in $n$, and let $k$ be a constant. Use the definitions of the asymptotic notations to prove the following properties

\begin{enumerate}[(a)]
    \item If $k \geq d$, then $p(n) = O(n^k)$.
    \item If $k \leq d$, then $p(n) = \Omega(n^k)$.
    \item If $k = d$, then $p(n) = \Theta(n^k)$.
    \item If $k > d$, then $p(n) = o(n^k)$.
    \item If $k < d$, then $p(n) = \omega(n^k)$.
\end{enumerate}

\sol \qed

\qn{3-2} \textbf{Relative asymptotic growths}

Indicate, for each pair of expressions $(A,B)$ in the table below, whether $A$ is $O, o, \Omega, \omega$ or $\Theta$ of $B$. Assume that $k \geq 1, \, \varepsilon > 0$, and $c > 1$ are constants. Your answer should be in the form of the table with ``yes'' or ``no'' written in each box.

\,

\begin{center}
\begin{tabular}{|l|l||l|l|l|l|l|}
    \hline
    A           & B                 & $O$ & $o$ & $\Omega$ & $\omega$ & $\Theta$ \\\hline\hline
    $\lg^k n$   & $n^{\varepsilon}$ &  Yes   & Yes    &  No        &   No       &   No                      \\\hline
    $n^k$       & $c^n$             &   Yes  &  Yes   &  No        &  No        &   No                      \\\hline
    $\sqrt{n}$  & $n^{\sin n}$      &   No  & No    &   No       & No         &  No                       \\\hline
    $2^n$       & $2^{n/2}$         &  No   &  No   & Yes         & Yes         & No                        \\\hline
    $n^{\lg c}$ & $c^{\lg n}$       &  Yes   & No    &  Yes        &   No       & Yes                        \\\hline
    $\lg(n!)$   & $\lg(n^n)$        &  Yes   &  No   &   Yes       &   No       &  Yes                      \\\hline
\end{tabular}
\end{center}
\qed

\qn{3-3} \textbf{Ordering by asymptotic growth rates}
\begin{enumerate}[(a)]
    \item Rank the following functions by order of growth; that is, find an arrangement $g_1, g_2, \dots, g_{30}$ of the functions satisfying $g_1 = \Omega(g_2)$, $g_2 = \Omega(g_3), \dots, g_{29} = \Theta(g_{30})$. Partition your list into equivalence classes such that functions $f(n)$ and $g(n)$ are in the same class iff $f(n) = \Theta(g(n))$.
    
\begin{center}
    \begin{tabular}{llllll}
        $\lg(\lg^* n)$     & $2^{\lg^* n}$         & $(\sqrt{2})^{\lg n}$ & $n^2$           & $n!$      & $(\lg n)!$     \\
        $(\frac{3}{2})^n$ & $n^3$                & $\lg^2 n$            & $\lg(n!)$       & $2^{2^n}$ & $n^{1/\lg n}$  \\
        $\ln \ln n$       & $\lg^* n$             & $n\cdot 2^n$         & $n^{\lg \lg n}$ & $\ln n$   & 1              \\
        $2^{\lg n}$       & $(\lg n)^{\lg n}$    & $e^n$                & $4^{\lg n}$     & $(n+1)!$  & $\sqrt{\lg n}$ \\
        $\lg^* (\lg n)$    & $2^{\sqrt{2 \lg n}}$ & $n$                  & $2^n$           & $n \lg n$ & $2^{2^{n+1}}$ 
        \end{tabular}
\end{center}

    \item Give an example of a single nonnegative function $f(n)$ such that for all functions $g_i(n)$ in part (a), $f(n)$ is neither $O(g_i(n))$ nor $\Omega(g_i(n))$.
\end{enumerate}

\sol \qed

\qn{3-4} \textbf{Asymptotic notation properties}

Let $f(n)$ and $g(n)$ be asymptotically positive functions. Prove or disprove each of the following conjectures.

\begin{enumerate}[(a)]
    \item $f(n) = O(g(n))$ implies $g(n) = O(f(n))$.
    \item $f(n) + g(n) = \Theta(\min(f(n), g(n)))$.
    \item $f(n) = O(g(n))$ implies $\lg(f(n)) = O(\lg(g(n)))$, where $\lg(g(n)) \geq 1$ and $f(n) \geq 1$ for all sufficiently large $n$.
    \item $f(n) = O(g(n))$ implies $2^{f(n)} = O(2^{g(n)})$.
    \item $f(n) = O((f(n))^2)$.
    \item $f(n) = O(g(n))$ implies $g(n) = \Omega(f(n))$.
    \item $f(n) = \Theta(f(n/2))$
    \item $f(n) + o(f(n)) = \Theta(f(n))$.
\end{enumerate}

\sol \begin{enumerate}[(a)]
    \item False. Let $f(n) = n$ and $g(n) = n^2$.
    \item False. Let $f(n) = n$ and $g(n) = n^2$.
    \item alkfj
    \item alkfj
    \item False. Let $f(n) = \frac{1}{n}$.
\end{enumerate}\qed

\qn{3-5} \textbf{Variations on $O$ and $\Omega$}

Some authors define $\Omega$ in a slightly different way than we do; let's use $\Omega_\infty$ (read ``omega infinity'') for this alternative definition. We say that $f(n) = \Omega_\infty(g(n))$ if there exists a positive constant $c$ such that $f(n) \geq cg(n) \geq 0$ for infinitely many positive integers $n$.

\begin{enumerate}[(a)]
    \item Show that for any two functions $f(n)$ and $g(n)$ that are asymptotically nonnegative, either $f(n) = O(g(n))$ or $f(n) = \Omega_\infty (g(n))$ or both, whereas this is not true if we use $\Omega$ in place of $\Omega_\infty$.
    \item Describe the potential advantages and disadvantages of using $\Omega_\infty$ instead of $\Omega$ to characterize the running times of programs.
\end{enumerate}

Some authors also definte $O$ in a slightly different manner; let's use $O'$ for the alternative definition. We say that $f(n) = O'(g(n))$ iff $|f(n)| = O(g(n))$.

\begin{enumerate}[(a)]
    \setcounter{enumi}{2}
    \item What happens to each direction of the ``if and only if'' in Theorem 3.1 if we substitute $O'$ for $O$ but still use $\Omega$?
\end{enumerate}

Some authors define $\tilde{O}$ (read ``soft-oh'') to mean $O$ with logarithmic factors ignored:

\begin{align*}
\tilde{O}(g(n)) = \{f(n) : \, & \text{there exist positive constants } c, \, k, \text{ and } n_0 \text{ such that} \\
& 0 \leq f(n) \leq cg(n) \lg^k (n) \text{ for all } n \geq n_0\}.
\end{align*}

\begin{enumerate}[(a)]
    \setcounter{enumi}{3}
    \item Definte $\tilde{\Omega}$ and $\tilde{\Theta}$ in a similar manner. Prove the corresponding analog to Theorem 3.1.
\end{enumerate}

\sol \qed

\qn{3-6} \textbf{Iterated functions}

We can apply the iteration operator $^*$ used in the $\lg^*$ function to any monotonically increasing function $f(n)$ over the reals. For a given constant $c \in \R$, we define the iterated function $f_c^*$ by $$f_c^*(n) = \min\{i \geq 0 \, : \, f^{(i)}(n) \leq c\},$$ which need not be well defined in all cases. In other words, the quantity $f_c^*(n)$ is the number of iterated applications of the function $f$ required to reduce its argument down to $c$ or less.

For each of the following functions $f(n)$ and constants $c$, give as tight of a bound as possible on $f_c^*(n).$

\begin{enumerate}[(a)]
    \item $f(n) = n-1, \, c=0$.
    \item $f(n) = \lg n, \, c=1$.
    \item $f(n) = n/2, \, c=1$.
    \item $f(n) = n/2, \, c=2$.
    \item $f(n) = \sqrt{n}, \, c=2$.
    \item $f(n) = \sqrt{n}, \, c=1$.
    \item $f(n) = n^{1/3}, \, c=2$.
    \item $f(n) = n/\lg n, \, n=2$.
\end{enumerate}

\sol \qed